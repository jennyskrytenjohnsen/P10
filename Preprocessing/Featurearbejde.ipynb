{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import vitaldb\n",
    "import pandas as pd\n",
    "import requests\n",
    "import json\n",
    "import io\n",
    "import time  # Importer time-modulet\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#APTT\n",
    "\n",
    "#Download clinical information\n",
    "clinical_information_url = \"https://api.vitaldb.net/cases\"\n",
    "df_clinical= pd.read_csv(clinical_information_url)\n",
    "\n",
    "#File with binary ICU admission infromation\n",
    "url = 'https://raw.githubusercontent.com/jennyskrytenjohnsen/P10/refs/heads/main/For_machinelearning/number_of_days_in_ICU.csv'\n",
    "pat_in_ICU = pd.read_csv(url)\n",
    "\n",
    "\n",
    "\n",
    "#Created a new dataframe for this task with caseid, aptt values and  binary ICu admission info\n",
    "df_caseidAndVariable =df_clinical[['caseid','preop_aptt']]\n",
    "df_caseidAndVariableICUInformation = pd.concat([df_caseidAndVariable, pat_in_ICU['icu_days_binary']], axis=1)\n",
    "df_caseidAndVariableICUInformation=df_caseidAndVariableICUInformation.dropna()\n",
    "\n",
    "#Allocated space\n",
    "binary=[]\n",
    "level_division = []\n",
    "extreme_level_division = []\n",
    "\n",
    "\n",
    "#for loop for creating the different data distrubations\n",
    "for index, row in df_caseidAndVariableICUInformation.iterrows():\n",
    "    if row['preop_aptt'] < 20:\n",
    "        extreme_level_division.append('-2')\n",
    "        level_division.append('-1')\n",
    "        binary.append('1')\n",
    "    elif row['preop_aptt'] < 25:\n",
    "        level_division.append('-1')\n",
    "        binary.append('1')\n",
    "        extreme_level_division.append('-1')\n",
    "    elif 25 <= row['preop_aptt'] <= 35:\n",
    "        binary.append('0') \n",
    "        level_division.append('0')\n",
    "        extreme_level_division.append('0')\n",
    "    elif row['preop_aptt'] > 35:\n",
    "        level_division.append('1')\n",
    "        binary.append('1')\n",
    "        extreme_level_division.append('1')\n",
    "    elif row['preop_aptt'] > 50:\n",
    "        extreme_level_division.append('2')\n",
    "        level_division.append('1')\n",
    "        binary.append('1')\n",
    "\n",
    "#Add new info to dataframe\n",
    "df_caseidAndVariableICUInformation['binary'] = binary\n",
    "df_caseidAndVariableICUInformation['level_division'] = level_division\n",
    "df_caseidAndVariableICUInformation['extreme_level_division'] = extreme_level_division\n",
    "\n",
    "\n",
    "print('-------------------------------------------------------------------------------------------')\n",
    "\n",
    "#Gives a nice overwiev over the new dataframe :)))\n",
    "print(df_caseidAndVariableICUInformation.head())\n",
    "###################################################################################################\n",
    "\n",
    "#Plotes the first plot, you can change the hue variable\n",
    "sns.countplot(x ='icu_days_binary', hue = \"extreme_level_division\", data = df_caseidAndVariableICUInformation)\n",
    "plt.title('aPTT Levels by ICU Admission Status')\n",
    "plt.ylabel(\"Patient Counts\")\n",
    "plt.xlabel(\" \")\n",
    "plt.xticks([0, 1], ['No ICU', 'ICU Admitted'])\n",
    "plt.legend(title='aTTP values (s) ', loc='upper right', labels=['25 < aTTP < 35', 'aTTP > 35', ' aTTP < 25 ', 'aTTP < 20', 'aTTP < 50'])\n",
    "plt.show()\n",
    "\n",
    "#Creates a new dataframe for evaluating the recored aptt values\n",
    "df_atppAndICUBinary= df_caseidAndVariableICUInformation[['preop_aptt', 'icu_days_binary']]\n",
    "\n",
    "# Split the data\n",
    "aptt_icu0 = df_atppAndICUBinary[df_atppAndICUBinary['icu_days_binary'] == 0]['preop_aptt']\n",
    "aptt_icu1 = df_atppAndICUBinary[df_atppAndICUBinary['icu_days_binary'] == 1]['preop_aptt']\n",
    "\n",
    "print(aptt_icu0)\n",
    "\n",
    "# Plot both histograms\n",
    "plt.hist(aptt_icu0, bins=[10, 15, 20, 25, 30, 40, 45, 50, 55],  label='ICU = 0 (Not admitted)', ec='black')\n",
    "plt.hist(aptt_icu1, bins=[10, 15, 20, 25, 30, 40, 45, 50, 55], label='ICU = 1 (Admitted)', ec='black')\n",
    "\n",
    "# Labels and legend\n",
    "plt.xlabel(\"Preoperative aPTT\")\n",
    "plt.xlim(0,70)\n",
    "plt.ylabel(\"Number of Patients\")\n",
    "plt.title(\"Distribution of APTT by ICU Admission\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "df_caseidAndVariableICUInformation = df_caseidAndVariableICUInformation.drop(columns=['icu_days_binary', 'binary', 'level_division', 'extreme_level_division'])\n",
    "\n",
    "\n",
    "df_caseidAndVariableICUInformation.rename(columns={\n",
    "    'caseid': 'CaseID',\n",
    "    'preop_aptt': 'Variable_PreopAptt'}, inplace=True)\n",
    "\n",
    "df_caseidAndVariableICUInformation.to_csv('Data_PreopAptt.csv', index=False)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## VASOACTIVE DRUGS\n",
    "\n",
    "import vitaldb  \n",
    "import requests\n",
    "import pandas as pd\n",
    "import io\n",
    "\n",
    "# Load clinical dataset from the VitalDB API\n",
    "clinical_data_url = \"https://api.vitaldb.net/cases\"\n",
    "df_clinical = pd.read_csv(clinical_data_url)\n",
    "\n",
    "# Extract 'intraop_eph' column and count missing values\n",
    "missing_eph = df_clinical[\"intraop_eph\"].isna().sum()\n",
    "print(f\"Missing values in 'intraop_eph': {missing_eph}\")\n",
    "\n",
    "# Extract 'intraop_phe' column and count missing values\n",
    "missing_phe = df_clinical[\"intraop_phe\"].isna().sum()\n",
    "print(f\"Missing values in 'intraop_phe': {missing_phe}\")\n",
    "\n",
    "# Load tracklist data from the VitalDB API\n",
    "track_list_url = \"https://api.vitaldb.net/trks\"\n",
    "df_tracklist = pd.read_csv(track_list_url)\n",
    "\n",
    "# List of special variables you're interested in (update as necessary)\n",
    "special_variables = [\n",
    "    \"Orchestra/NEPI_VOL\",\n",
    "    \"Orchestra/EPI_VOL\",\n",
    "    \"Orchestra/PHEN_VOL\",\n",
    "    \"Orchestra/VASO_VOL\",\n",
    "    \"Orchestra/DOPA_VOL\",\n",
    "    \"Orchestra/DOBU_VOL\",\n",
    "    \"Orchestra/MRN_VOL\"\n",
    "]\n",
    "\n",
    "# Initialize a list to store the results for each caseid\n",
    "results = []\n",
    "\n",
    "def collect_track_last_value():\n",
    "    # Iterate over each caseid in the clinical dataset\n",
    "    for index, row in df_clinical.iterrows():\n",
    "        caseid = row[\"caseid\"]\n",
    "\n",
    "        # Initialize the values for the current caseid\n",
    "        value_vaso = 0  # Default to 0 for value_vaso\n",
    "        value_eph = 0  # Default to 0 for value_eph\n",
    "        value_phe = 0  # Default to 0 for value_phe\n",
    "        value_ino = 0  # Default to 0 for value_ino\n",
    "\n",
    "        # Get the value of intraop_eph from the clinical dataset\n",
    "        intraop_eph = row[\"intraop_eph\"]\n",
    "        if pd.notna(intraop_eph) and intraop_eph != 0:\n",
    "            value_eph = 1\n",
    "\n",
    "        # Get the value of intraop_phe from the clinical dataset\n",
    "        intraop_phe = row[\"intraop_phe\"]\n",
    "        if pd.notna(intraop_phe) and intraop_phe != 0:\n",
    "            value_phe = 1\n",
    "\n",
    "        # Variables to track if the last value is non-zero\n",
    "        non_zero_count_ino = 0\n",
    "\n",
    "        # Iterate over the special variables and check if any have non-zero values for the current caseid\n",
    "        for var in special_variables:\n",
    "            track_row = df_tracklist[df_tracklist['tname'] == var]\n",
    "            if not track_row.empty:\n",
    "                trackidentifier = track_row.iloc[0][\"tid\"]\n",
    "                trackdata_url = f\"https://api.vitaldb.net/{trackidentifier}\"\n",
    "\n",
    "                # Handle API error\n",
    "                try:\n",
    "                    response = requests.get(trackdata_url, timeout=10)\n",
    "                    response.raise_for_status()\n",
    "                except requests.exceptions.Timeout:\n",
    "                    print(f\"Timeout error: Cannot get {var} ({trackdata_url})\")\n",
    "                    continue  # Skip to next track\n",
    "\n",
    "                try:\n",
    "                    # Convert API response into a pandas DataFrame\n",
    "                    trackdata = pd.read_csv(io.StringIO(response.text))\n",
    "                    if trackdata.empty:\n",
    "                        continue\n",
    "                except:\n",
    "                    continue  # Skip if there is an issue reading the track data\n",
    "\n",
    "                # Get the last value of the track data\n",
    "                last_value = trackdata[var].iloc[-1] if var in trackdata.columns else 0\n",
    "\n",
    "                # Set value_vaso to 1 if the last value is non-zero\n",
    "                if last_value != 0:\n",
    "                    value_vaso = 1\n",
    "\n",
    "                # For value_ino, track only NEPI_VOL, EPI_VOL, and DOPA_VOL\n",
    "                if var in [\"Orchestra/NEPI_VOL\", \"Orchestra/EPI_VOL\", \"Orchestra/DOPA_VOL\"]:\n",
    "                    if last_value != 0:\n",
    "                        non_zero_count_ino += 1\n",
    "\n",
    "        # Set value_ino to 1 if exactly one of the three variables had a non-zero value\n",
    "        if non_zero_count_ino == 1:\n",
    "            value_ino = 1\n",
    "\n",
    "        # Append the results for the current caseid\n",
    "        results.append({\n",
    "            \"caseid\": caseid,\n",
    "            \"value_eph\": value_eph,\n",
    "            \"value_phe\": value_phe,\n",
    "            \"value_vaso\": value_vaso,\n",
    "            \"value_ino\": value_ino\n",
    "        })\n",
    "\n",
    "    # Save the results to a CSV file in the 'Data' folder\n",
    "    output_file = \"C:/Users/mariah/Documents/GitHub/P10/Preprocessing/Data/Data_vasoactivedrugs.csv\"\n",
    "    df_results = pd.DataFrame(results)\n",
    "    df_results.to_csv(output_file, index=False)\n",
    "    print(f\"Data saved to {output_file}\")\n",
    "\n",
    "# Run the function\n",
    "collect_track_last_value()\n",
    "\n",
    "#### PLOTTE KODE ####\n",
    "\n",
    "# import requests\n",
    "# import pandas as pd\n",
    "# import io\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# # List of special variables you're interested in (update as necessary)\n",
    "# special_variables = [\"Orchestra/NEPI_VOL\"]\n",
    "\n",
    "# # Load the tracklist data\n",
    "# track_list_url = \"https://api.vitaldb.net/trks\"\n",
    "# df_tracklist = pd.read_csv(track_list_url)\n",
    "\n",
    "# # Get the first caseid from the dataframe\n",
    "# first_caseid = 17\n",
    "\n",
    "# # Iterate through the tracklist to find the track for the first caseid\n",
    "# for index, row in df_tracklist.iterrows():\n",
    "#     if row['tname'] in special_variables and row[\"caseid\"] == first_caseid:\n",
    "#         trackidentifier = row[\"tid\"]\n",
    "#         trackdata_url = f\"https://api.vitaldb.net/{trackidentifier}\"\n",
    "        \n",
    "#         # Handle API error\n",
    "#         try:\n",
    "#             response = requests.get(trackdata_url, timeout=10)\n",
    "#             response.raise_for_status()\n",
    "#         except requests.exceptions.Timeout:\n",
    "#             print(f\"Timeout error: Cannot get {row['tname']} ({trackdata_url})\")\n",
    "#             continue  # Skip to next track\n",
    "\n",
    "#         try:\n",
    "#             # Convert API response into a pandas DataFrame\n",
    "#             trackdata = pd.read_csv(io.StringIO(response.text))\n",
    "#             if trackdata.empty:\n",
    "#                 print(f\"Track data for track {row['tname']} is empty.\")\n",
    "#                 continue\n",
    "#         except Exception as e:\n",
    "#             print(f\"Error reading track data for track {row['tname']}: {e}\")\n",
    "#             continue  # Skip if there is an issue reading the track data\n",
    "\n",
    "#         # Debugging: Check the first few rows of the data\n",
    "#         print(f\"First few rows of track data for caseid {first_caseid}:\")\n",
    "#         print(trackdata.head())\n",
    "\n",
    "#         # Check if 'Time' and 'Orchestra/NEPI_VOL' columns exist\n",
    "#         if 'Time' not in trackdata.columns or 'Orchestra/NEPI_VOL' not in trackdata.columns:\n",
    "#             print(f\"Columns 'Time' and/or 'Orchestra/NEPI_VOL' not found in track data.\")\n",
    "#             continue\n",
    "\n",
    "#         # Extract 'Time' and 'Orchestra/NEPI_VOL' columns\n",
    "#         time_data = trackdata[\"Time\"]\n",
    "#         track_values = trackdata[\"Orchestra/NEPI_VOL\"]\n",
    "\n",
    "#         # Check if the columns have valid data\n",
    "#         if time_data.empty or track_values.empty:\n",
    "#             print(f\"Empty data for 'Time' or 'Orchestra/NEPI_VOL' in track data for caseid {first_caseid}.\")\n",
    "#             continue\n",
    "\n",
    "#         # Plot the data\n",
    "#         plt.figure(figsize=(10, 6))\n",
    "#         plt.plot(time_data, track_values, label='Orchestra/NEPI_VOL', color='b')\n",
    "#         plt.xlabel(\"Time\")\n",
    "#         plt.ylabel(\"Orchestra/NEPI_VOL Value\")\n",
    "#         plt.title(f\"Track Values Over Time for Case ID: {first_caseid}\")\n",
    "#         plt.xticks(rotation=45)\n",
    "#         plt.grid(True)\n",
    "#         plt.legend()\n",
    "#         plt.tight_layout()\n",
    "#         plt.show()\n",
    "\n",
    "#         break  # We only need the first caseid, so break the loop after plotting\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### FFP and RBC ###\n",
    "\n",
    "import vitaldb  \n",
    "import requests\n",
    "import pandas as pd\n",
    "import io\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load clinical dataset from the VitalDB API\n",
    "clinical_data_url = \"https://api.vitaldb.net/cases\"\n",
    "df_clinical = pd.read_csv(clinical_data_url)\n",
    "\n",
    "# Access intraop_rbc, intraop_ffp, and icu_days columns\n",
    "intraop_rbc = df_clinical['intraop_rbc']\n",
    "intraop_ffp = df_clinical['intraop_ffp']\n",
    "icu_days = df_clinical['icu_days']\n",
    "\n",
    "# Create a new column to categorize whether the patient went to ICU (ICU or No ICU)\n",
    "df_clinical['icu_status'] = icu_days.apply(lambda x: 'ICU' if x != 0 else 'No ICU')\n",
    "\n",
    "# Group the data by ICU status\n",
    "grouped = df_clinical.groupby('icu_status')\n",
    "\n",
    "# Calculate total transfusion per group\n",
    "total_transfusion = grouped[['intraop_rbc', 'intraop_ffp']].sum()\n",
    "\n",
    "# Count number of patients in each group\n",
    "patient_counts = grouped.size()\n",
    "\n",
    "# Normalize transfusion by number of patients\n",
    "normalized_transfusion = total_transfusion.div(patient_counts, axis=0)\n",
    "\n",
    "# Reorder rows so that 'No ICU' is first\n",
    "normalized_transfusion = normalized_transfusion.loc[['No ICU', 'ICU']]\n",
    "\n",
    "# Plot the normalized results\n",
    "plt.figure(figsize=(10, 6))\n",
    "normalized_transfusion.plot(kind='bar', ax=plt.gca(), color=['blue', 'red'], alpha=0.7)\n",
    "\n",
    "# Add labels and title\n",
    "plt.xlabel('ICU Status')\n",
    "plt.ylabel('Average Blood Transfusion Units per Patient')\n",
    "plt.title('Average Blood Transfusion (RBC & FFP) per Patient for ICU and No ICU Groups')\n",
    "plt.xticks(rotation=0)\n",
    "plt.legend(title=\"Blood Product\", labels=['RBC', 'FFP'])\n",
    "\n",
    "# Display the plot\n",
    "plt.show()\n",
    "\n",
    "# -------- Save FFP and RBC data to CSV --------\n",
    "# Create new DataFrame with caseid, FFP and RBC\n",
    "df_transfusion = df_clinical[['caseid', 'intraop_ffp', 'intraop_rbc']].copy()\n",
    "\n",
    "# Rename columns to match requested format\n",
    "df_transfusion.rename(columns={'intraop_ffp': 'FFP', 'intraop_rbc': 'RBC'}, inplace=True)\n",
    "\n",
    "# Replace missing values with 0\n",
    "df_transfusion.fillna(0, inplace=True)\n",
    "\n",
    "# Save to CSV in the specified path\n",
    "output_path = 'C:/Users/mariah/Documents/GitHub/P10/Preprocessing/Data/Data_FFPandRBC.csv'\n",
    "df_transfusion.to_csv(output_path, index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
